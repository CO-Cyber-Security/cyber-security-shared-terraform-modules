version: 0.2

env:
  shell: bash

phases:
  build:
    commands:
      - set -euo pipefail
      - echo "getting required actions..."
      - export OUTPUT_ARTIFACT_PATH="${OUTPUT_ARTIFACT_PATH:-actions_required.json}"
      - export CHANGED_FILES_ARTIFACT="${CHANGED_FILES_ARTIFACT:-changed_files}"
      - export CHANGED_FILES_JSON="${CHANGED_FILES_JSON:-/changed_files.json}"
      - export ACTION_TRIGGERS_ARTIFACT="${ACTION_TRIGGERS_ARTIFACT:-}"
      - export ACTION_TRIGGERS_JSON="${ACTION_TRIGGERS_JSON:-/terraform/modules/codepipeline_prodpython/action_triggers.json}"

      - |
        artifact_dir() {
          local name="$1"
          if [ -z "$name" ]; then
            printf '%s' "$CODEBUILD_SRC_DIR"
          else
            local var="CODEBUILD_SRC_DIR_${name}"
            if [ -n "${!var-}" ]; then
              printf '%s' "${!var}"
            else
              printf ''
            fi
          fi
        }
      - CHANGED_FILES_PATH="$(artifact_dir "$CHANGED_FILES_ARTIFACT")"
      - ACTION_TRIGGERS_PATH="$(artifact_dir "$ACTION_TRIGGERS_ARTIFACT")"
      - CHANGED_FILES="${CHANGED_FILES_PATH%/}${CHANGED_FILES_JSON}"
      - ACTION_TRIGGERS="${ACTION_TRIGGERS_PATH%/}${ACTION_TRIGGERS_JSON}"

      - echo "CHANGED_FILES_PATH=$CHANGED_FILES_PATH"
      - echo "ACTION_TRIGGERS_PATH=$ACTION_TRIGGERS_PATH"
      - echo "CHANGED_FILES=$CHANGED_FILES"
      - echo "ACTION_TRIGGERS=$ACTION_TRIGGERS"
      - ls -lah "$CHANGED_FILES_PATH" || true
      - ls -lah "$ACTION_TRIGGERS_PATH" || true
      - test -f "$CHANGED_FILES" && wc -c "$CHANGED_FILES" || echo "missing: $CHANGED_FILES"
      - test -f "$ACTION_TRIGGERS" && wc -c "$ACTION_TRIGGERS" || echo "missing: $ACTION_TRIGGERS"

      # -------- Artifact checks: record and show failing files --------
      - export ARTIFACT_ERRS=/tmp/artifact_errors.txt
      - truncate -s 0 "$ARTIFACT_ERRS"
      - |
        show_file_for_review() {
          local p="$1"
          [ -f "$p" ] || return 0
          echo "----- BEGIN FILE: $p -----"
          local lines; lines=$(wc -l < "$p" 2>/dev/null || echo 0)
          if [ "$lines" -le 200 ]; then
            sed -n '1,200p' "$p" || true
          else
            sed -n '1,120p' "$p" || true
            echo "----- [snip] -----"
            tail -n 80 "$p" || true
          fi
          echo "----- END FILE: $p -----"
        }
        check_json_artifact() {
          local name="$1" path="$2"
          if [ -z "${path:-}" ]; then
            echo "ART_FAIL|$name|unresolved_path||" >> "$ARTIFACT_ERRS"
            echo "Artifact failure: '$name' has unresolved path"
            return 1
          fi
          if [ ! -f "$path" ]; then
            echo "ART_FAIL|$name|missing|$path|" >> "$ARTIFACT_ERRS"
            echo "Artifact failure: '$name' missing at $path"
            return 1
          fi
          if [ ! -s "$path" ]; then
            echo "ART_FAIL|$name|empty|$path|" >> "$ARTIFACT_ERRS"
            echo "Artifact failure: '$name' is empty at $path"
            return 1
          fi
          if ! python3 - <<'PY' "$path" 2>/tmp/j.err; then
import json, sys
with open(sys.argv[1], "r", encoding="utf-8-sig") as f:
    json.load(f)
PY
          then
            local err; err="$(tr -d '\n' </tmp/j.err | head -c 500 || true)"
            echo "ART_FAIL|$name|invalid_json|$path|$err" >> "$ARTIFACT_ERRS"
            echo "Artifact failure: '$name' has invalid JSON at $path"
            show_file_for_review "$path" || true
            return 1
          fi
          return 0
        }
      - check_json_artifact "changed_files" "$CHANGED_FILES" || { echo "{}" > "${CHANGED_FILES}.fallback"; CHANGED_FILES="${CHANGED_FILES}.fallback"; }
      - check_json_artifact "action_triggers" "$ACTION_TRIGGERS" || { echo "{}" > "${ACTION_TRIGGERS}.fallback"; ACTION_TRIGGERS="${ACTION_TRIGGERS}.fallback"; }

      - export FILE_LIST_TXT=/tmp/changed_files.txt
      - |
        python3 - <<'PY'
        import json, os, glob
        src_dir = os.environ.get("CODEBUILD_SRC_DIR", ".")
        changed_json = os.environ.get("CHANGED_FILES")
        files = []
        def flatten(v):
          if isinstance(v, str): return [v]
          if isinstance(v, list): return [x for x in v if isinstance(x, str)]
          if isinstance(v, dict):
            out=[]
            for _,val in v.items():
              out += flatten(val)
            return out
          return []
        if changed_json and os.path.isfile(changed_json) and os.path.getsize(changed_json)>0:
          try:
            with open(changed_json, "r", encoding="utf-8-sig") as f:
              data = json.loads(f.read().strip() or "[]")
            files = flatten(data)
          except Exception:
            files = []
        if not files:
          for pat in ["**/*.yml","**/*.yaml","**/*.tf"]:
            files += glob.glob(os.path.join(src_dir, pat), recursive=True)
        norm = []
        for p in files:
          p = os.path.normpath(os.path.join(src_dir, p)) if not os.path.isabs(p) else os.path.normpath(p)
          if os.path.isfile(p):
            norm.append(p)
        norm = sorted(set(norm))
        with open("/tmp/changed_files.txt","w") as out:
          out.write("\n".join(norm))
        PY
      - echo "Candidate files:"
      - sed -n '1,200p' "$FILE_LIST_TXT" || true

      - export YAML_LIST=/tmp/yaml_files.txt
      - export TF_LIST=/tmp/tf_files.txt
      - grep -Ei '\.(yml|yaml)$' "$FILE_LIST_TXT" > "$YAML_LIST" || true
      - grep -Ei '\.tf$' "$FILE_LIST_TXT" > "$TF_LIST" || true

      - export PATH="$HOME/.local/bin:$PATH"
      - pip3 install --user --quiet yamllint || pip install --user --quiet yamllint
      - |
        if ! command -v terraform >/dev/null 2>&1; then
          TF_VERSION="${TF_VERSION:-1.6.6}"
          echo "Installing Terraform ${TF_VERSION}..."
          curl -sSLo /tmp/terraform.zip "https://releases.hashicorp.com/terraform/${TF_VERSION}/terraform_${TF_VERSION}_linux_amd64.zip"
          unzip -o /tmp/terraform.zip -d /usr/local/bin
          terraform -version
        fi


      - export YAML_ERRS=/tmp/yaml_errors.txt
      - truncate -s 0 "$YAML_ERRS"
      - |
        if [ -s "$YAML_LIST" ]; then
          while IFS= read -r f; do
            if ! yamllint -f parsable -d "{extends: default, rules: {line-length: {max: 160}, document-start: disable}}" "$f" > /tmp/y.out 2>&1; then
              echo "YAML_FAIL|$f" >> "$YAML_ERRS"
              sed 's/^/  /' /tmp/y.out >> "$YAML_ERRS"
            fi
          done < "$YAML_LIST"
        fi

      - export TF_ERRS=/tmp/tf_errors.txt
      - truncate -s 0 "$TF_ERRS"
      - |
        if [ -s "$TF_LIST" ]; then
          mapfile -t TF_DIRS < <(awk -F/ 'NF{NF--;print}' "$TF_LIST" | sed 's#^$#.#' | sort -u)
          for d in "${TF_DIRS[@]}"; do
            echo "Checking Terraform in: $d"
            if ! terraform -chdir="$d" init -backend=false -input=false -no-color >/tmp/tf_init.out 2>&1; then
              echo "TF_FAIL|$d|init" >> "$TF_ERRS"
              sed 's/^/  /' /tmp/tf_init.out >> "$TF_ERRS"
              continue
            fi
            if ! terraform -chdir="$d" validate -no-color >/tmp/tf_val.out 2>&1; then
              echo "TF_FAIL|$d|validate" >> "$TF_ERRS"
              sed 's/^/  /' /tmp/tf_val.out >> "$TF_ERRS"
            fi
            if ! terraform -chdir="$d" fmt -check -no-color >/tmp/tf_fmt.out 2>&1; then
              echo "TF_FAIL|$d|fmt" >> "$TF_ERRS"
              sed 's/^/  /' /tmp/tf_fmt.out >> "$TF_ERRS"
            fi
          done
        fi

      - truncate -s 0 "$OUTPUT_ARTIFACT_PATH"
      - |
        python3 - <<'PY'
        import json, os
        out = {"artifact_failures": [], "yaml_failed": [], "terraform_failed": [], "summary": {}}
        def read_lines(path):
          if not os.path.isfile(path) or os.path.getsize(path)==0:
            return []
          with open(path,"r",encoding="utf-8") as f:
            return f.read().splitlines()
        # Artifact failures
        for line in read_lines(os.environ.get("ARTIFACT_ERRS","/tmp/artifact_errors.txt")):
          if not line.startswith("ART_FAIL|"): continue
          parts = line.split("|", 4)
          out["artifact_failures"].append({
            "artifact": parts[1] if len(parts)>1 else "",
            "reason":   parts[2] if len(parts)>2 else "",
            "path":     parts[3] if len(parts)>3 else "",
            "detail":   parts[4] if len(parts)>4 else "",
          })
        # YAML failures
        y = read_lines(os.environ.get("YAML_ERRS","/tmp/yaml_errors.txt"))
        cur = None
        for line in y:
          if line.startswith("YAML_FAIL|"):
            _, fpath = line.split("|",1)
            cur = {"file": fpath, "errors": []}
            out["yaml_failed"].append(cur)
          else:
            if cur is not None and line.strip():
              cur["errors"].append(line.strip())
        for item in out["yaml_failed"]:
          item["errors"] = "\n".join(item["errors"])
        # Terraform failures
        t = read_lines(os.environ.get("TF_ERRS","/tmp/tf_errors.txt"))
        cur = None
        for line in t:
          if line.startswith("TF_FAIL|"):
            _, dpath, stage = line.split("|",2)
            cur = {"dir": dpath, "stage": stage, "errors": []}
            out["terraform_failed"].append(cur)
          else:
            if cur is not None and line.strip():
              cur["errors"].append(line.strip())
        for item in out["terraform_failed"]:
          item["errors"] = "\n".join(item["errors"])
        out["summary"] = {
          "artifact_failed_count": len(out["artifact_failures"]),
          "yaml_failed_count": len(out["yaml_failed"]),
          "terraform_failed_count": len(out["terraform_failed"]),
        }
        with open(os.environ.get("OUTPUT_ARTIFACT_PATH","actions_required.json"),"w",encoding="utf-8") as f:
          json.dump(out, f, indent=2)
        PY

      - mkdir -p /opt
      - mv "$OUTPUT_ARTIFACT_PATH" "/opt/$OUTPUT_ARTIFACT_PATH"
      - echo "Actions report:"
      - cat "/opt/$OUTPUT_ARTIFACT_PATH"

artifacts:
  name: ActionsRequired
  files:
    - $OUTPUT_ARTIFACT_PATH
  discard-paths: no
  base-directory: /opt
